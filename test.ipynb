{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1 december wereld aids dag voorlichting in zuidafrika over bieten taboes en optimisme', 'nl'), ('1 millón de afectados ante las inundaciones en sri lanka unicef está distribuyendo ayuda de emergencia srilanka', 'es'), ('1 millón de fans en facebook antes del 14 de febrero y paty miki dani y berta se tiran en paracaídas qué harías tú porunmillondefans', 'es'), ('1 satellite galileo sottoposto ai test presso lesaestec nl galileo navigation space in inglese', 'it'), ('10 der welt sind bei', 'de'), ('10 jaar voor overval op juwelier bejaard echtpaar werd zwaar mishandeld', 'nl'), ('10 trickiest spy gadgets ever', 'en'), ('100 m du grand emprunt seront dédiés lentreprenariat social et solidaire deux fois plus que ce qui était préconisé dans le rapport', 'fr'), ('1000 dank für den link taz eauto hatte ich noch nicht gelesen', 'de')]\n"
     ]
    }
   ],
   "source": [
    "#read data from data.csv\n",
    "data_file = open('data.csv',encoding=\"utf-8\")\n",
    "lines = data_file.readlines()\n",
    "data_file.close()\n",
    "# dataset:(sentence,tag)\n",
    "dataset = [(line.strip()[:-3],line.strip()[-2:]) for line in lines]\n",
    "print(dataset[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# x:langeges_sentences \n",
    "# y:tagas\n",
    "x, y = zip(*dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "import re \n",
    "def remove_noise(document):\n",
    "    # remove website, e_mail and tags\n",
    "    noise_pattern = re.compile(\"|\".join([\"http\\S+\",\"\\@\\w+\",\"\\#\\w+\"]))\n",
    "    clean_text = re.sub(noise_pattern,\"\",document)\n",
    "    return clean_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vec = CountVectorizer(\n",
    "    lowercase=True,          # lowercase the text\n",
    "    analyzer=\"char_wb\",      # tokenize by character ngrams\n",
    "    ngram_range=(1,2),       # use ngrams of size 1 and 2\n",
    "    max_features=1000,       # keep the most common 1000 ngrams\n",
    "    preprocessor=remove_noise# user this function to preprocess\n",
    ")\n",
    "\n",
    "vec.fit(x_train)\n",
    "\n",
    "def get_features(x):\n",
    "    return vec.fit_transform(x)\n",
    "    \n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(get_features(x_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'fr'], dtype='<U2')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(x_test), y_test)\n",
    "classifier.predict(vec.transform([\"This is an english sentence\",\"bon su\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
